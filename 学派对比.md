# 学派对比

机器学习中主要分为频率派以及贝叶斯学派。

其中，数据可以表示为:
$$
X :data \rightarrow X = (x_1,x_2,...,x_N)^T_{N*P} = \\
\left[
\begin{matrix}
x_{11},x_{12},...,x_{1p}\\
x_{21},x_{22},...,x_{2p}\\
...\\
x_{n1},x_{n2},...,x_{np}
\end{matrix}
\right]_{N*p}
$$


这个记号表示有 $N$ 个样本，每个样本都是 $p$ 维向量。然后针对于每一个样本都有$x \leftarrow p(x|\theta)$,其中$\theta$是参数，然后这两个学派主要就是针对这个参数是否已知来进行判别未知样本x。

## 频率派

频率派将$\theta$当作是未知的常量.

频率派就相当于统计机器学习

step1:构建模型

step2:构建损失函数

step3:优化



## 贝叶斯学派

贝叶斯学派将$\theta$当作是不是一个常量。这个 $\theta$ 满足一个预设的先验的分布 $\theta\sim p(\theta)$.

于是根据贝叶斯定理依赖观测集参数的后验可以写成：
$$
p(\theta|X)=\frac{p(X|\theta)\cdot p(\theta)}{p(X)}=\frac{p(X|\theta)\cdot p(\theta)}{\int\limits _{\theta}p(X|\theta)\cdot p(\theta)d\theta}
$$


为了求 $\theta$ 的值，我们要最大化这个参数后验MAP(为最大后验概率Maximum a posteriori)：
$$
 \theta_{MAP}=\mathop{argmax}\limits _{\theta}p(\theta|X)=\mathop{argmax}\limits _{\theta}p(X|\theta)\cdot p(\theta) 
$$


也就是说$X\rightarrow \theta \rightarrow \hat{x}$

